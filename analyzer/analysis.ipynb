{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd7f01-7564-40d3-a3dd-2e88bfbe7d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import powerlaw\n",
    "import statistics\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2276b-57ec-410c-bbeb-826320350373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(name):\n",
    "    graph_path = \"../graphs/{}.gml\".format(name)\n",
    "    return nx.read_gml(graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f3fbd-6b8d-4ac7-ac44-060797848030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chosen graph\n",
    "name = \"General Assembly/net_ga_all\"\n",
    "fname = f'{name}_filled'\n",
    "cname = f'{name}_cutoff'\n",
    "\n",
    "net = load_graph(name)\n",
    "fnet = load_graph(fname)\n",
    "cnet = load_graph(cname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245cc9be-1db7-4e76-9196-00724efbea9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Basic Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d935371-d439-4df6-aabd-ff12cd0479f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total countries: {net.number_of_nodes()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24f40d-c3fe-4267-8e2c-38142e030909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_density(net):\n",
    "    if net.number_of_nodes() < 2:\n",
    "        return 1\n",
    "\n",
    "    weights = (edge[2]['weight'] for edge in net.edges(data=True))\n",
    "    possible_edges = (net.number_of_nodes() * (net.number_of_nodes() - 1)) / 2\n",
    "    return sum(weights) / possible_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d6f10-12c2-44fc-a969-09d6516bf6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Density: {nx.density(net)}')\n",
    "print(f'Filled weighted density: {weighted_density(fnet)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f07ede5-7cdc-4adc-869d-45cfb5d3e5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rich club check based on the filled graph\n",
    "netDegrees = nx.degree(fnet, weight='weight')\n",
    "richClubNet = nx.subgraph(fnet, [x for x in fnet.nodes() if netDegrees[x] > 155])\n",
    "print(f'Rich Club of {richClubNet.number_of_nodes()} nodes - Weighted density: {weighted_density(richClubNet)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ed1bf-bfb1-4877-b08e-2a1979ca9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_is_connected = nx.is_connected(cnet)\n",
    "print(f'Cutoff is connected: {cutoff_is_connected}')\n",
    "if not cutoff_is_connected:\n",
    "    print(f'Cut-off number of components: {nx.number_connected_components(cnet)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05fc0b-6b35-4901-9b0e-44028e5050cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Filled average clustering: {nx.average_clustering(fnet, weight=\"weight\")}')\n",
    "print(f'Cut-off average clustering: {nx.average_clustering(cnet, weight=\"weight\")}')\n",
    "print(f'Cut-off global clustering: {nx.transitivity(cnet)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ecbd5a-7815-41f8-bffd-01887e81f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cut-off equivalent Erdos Renyi and ScaleFree networks\n",
    "n = cnet.number_of_nodes()\n",
    "m = cnet.number_of_edges()\n",
    "p = ( 2*float(m) ) / ( n* (n-1) )\n",
    "\n",
    "netER = nx.erdos_renyi_graph(n, p)\n",
    "netSFMulti = nx.scale_free_graph(n)\n",
    "\n",
    "netSF = nx.DiGraph()\n",
    "for u,v in netSFMulti.edges():\n",
    "    if netSF.has_edge(u,v):\n",
    "        netSF[u][v]['weight'] += 1\n",
    "    else:\n",
    "        netSF.add_edge(u, v, weight=1)\n",
    "        \n",
    "print(f'Cut-off ER average clustering: {nx.average_clustering(netER)}')\n",
    "print(f'Cut-off SF average clustering: {nx.average_clustering(netSF)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c918b47-5dc0-4b7a-b7a7-c3c2c442a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering(net, weight = None, logScale = False):\n",
    "    clustering = nx.clustering(net, weight=weight)\n",
    "    for key, value in clustering.items():\n",
    "        clustering[key] = math.floor(value * 40) / 40\n",
    "\n",
    "    clust_counts = Counter(clustering.values())\n",
    "    print(clust_counts)\n",
    "    x, y = zip(*clust_counts.items())\n",
    "\n",
    "    plt.ylabel('frequency')\n",
    "    plt.xlabel('weighted clustering') if weight != None else plt.xlabel('clustering')\n",
    "\n",
    "    plt.bar(clust_counts.keys(), clust_counts.values(), 0.025, align='edge', color='darkred', log=logScale, edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192f902-3e00-406c-8200-547b28744824",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering(fnet, weight = \"weight\", logScale = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe92f8a-2974-4f3b-a024-5081e99b4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_deg_frequency(net, weight = None, bracket_size=5):\n",
    "    degrees = dict(net.degree(weight=weight))\n",
    "    for key, value in degrees.items():\n",
    "        degrees[key] = bracket_size * round(value / bracket_size)\n",
    "\n",
    "    deg_counts = Counter(degrees.values())\n",
    "    print(deg_counts)\n",
    "    x, y = zip(*deg_counts.items())\n",
    "\n",
    "    plt.figure(1)\n",
    "    \n",
    "    plt.xlabel('weighted degree') if weight != None else plt.xlabel('degree')\n",
    "    plt.xscale('linear')\n",
    "    plt.xlim(min(x), max(x))\n",
    "\n",
    "    plt.ylabel('frequency')\n",
    "    plt.yscale('linear')\n",
    "    plt.ylim(1, max(y) * 1.1)\n",
    "\n",
    "    plt.scatter(x, y, marker='.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa651b-65b0-462e-9952-94584a68472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show filled graph weighted degree distrubution\n",
    "# Is it power-law?\n",
    "plot_deg_frequency(fnet, weight='weight', bracket_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffab92c-f016-4b00-8250-73cdfda7e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show cut-off graph weighted degree distrubution\n",
    "# Is it power-law?\n",
    "plot_deg_frequency(cnet, weight='weight', bracket_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273fc37-e09a-4aaa-b19e-d10f351bc9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Filled assortativity coefficient: {nx.degree_assortativity_coefficient(fnet, weight='weight')}\")\n",
    "print(f\"Cut-off assortativity coefficient: {nx.degree_assortativity_coefficient(cnet, weight='weight')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e77842-45a1-4592-9b58-9eeb67f28059",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Least and most friendly countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb7091f-6339-47f8-b88d-fd76252b474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average agreement for every country\n",
    "avg_agreements = {}\n",
    "for country_1 in net:\n",
    "    agreements = (net[country_1][country_2]['agreement'] for country_2 in net[country_1])\n",
    "    avg_agreements[country_1] = statistics.mean(agreements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a17fb-6423-4e47-a94b-4106bf4343c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Countries with highest average agreement:\\n')\n",
    "for k, v in sorted(avg_agreements.items(), key=lambda item: -item[1])[:10]:\n",
    "    print(f'{k}: {round(v * 100, 1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7dd85a-c919-4fd8-9dab-d32b9cdb3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Countries with lowest average agreement:\\n')\n",
    "for k, v in sorted(avg_agreements.items(), key=lambda item: item[1])[:10]:\n",
    "    print(f'{k}: {round(v * 100, 1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556b8a9-b2ee-43a7-9f7a-22d305aa0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_agreement(net, resolution = 0.025):\n",
    "    bracket_ratio = 1 / resolution\n",
    "    agreements = [ edge[2]['agreement'] for edge in net.edges(data=True) ]\n",
    "    \n",
    "    print(f'Median agreement: {statistics.median(agreements)}')\n",
    "    print(f'Average agreement: {statistics.fmean(agreements)}')\n",
    "    \n",
    "    agreements = list(map(lambda x: math.floor(x * bracket_ratio) / bracket_ratio, agreements))\n",
    "    agreement_counts = Counter(agreements)\n",
    "    print(agreement_counts)\n",
    "    x, y = zip(*agreement_counts.items())\n",
    "\n",
    "    plt.figure(1)\n",
    "    \n",
    "    plt.xlabel('agreement')\n",
    "    plt.xlim(0, max(x))\n",
    "\n",
    "    plt.ylabel('frequency')\n",
    "    plt.ylim(1, max(y) * 1.1)\n",
    "\n",
    "    plt.scatter(x, y, marker='.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acedf1e-d25e-43ff-abce-9b4cce1e238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the distribution of 'agreement' values\n",
    "plot_agreement(net, resolution = 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf9fb7-d697-4892-9e13-269b6d39c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_relationship_levels(net):\n",
    "    bad_threshold = 0.5\n",
    "    good_threshold = 0.787\n",
    "    great_threshhold = 0.95\n",
    "\n",
    "    agreements = [ edge[2]['agreement'] for edge in net.edges(data=True) ]\n",
    "    \n",
    "    total = len(agreements)\n",
    "    def to_percentage(val):\n",
    "        perc = val * 100 / total\n",
    "        return f'{round(perc)}%'\n",
    "    \n",
    "    abysmal = len(list(filter(lambda x: x < bad_threshold, agreements)))\n",
    "    bad = len(list(filter(lambda x: x >= bad_threshold and x < good_threshold, agreements)))\n",
    "    good = len(list(filter(lambda x: x >= good_threshold and x < great_threshhold, agreements)))\n",
    "    great = len(list(filter(lambda x: x >= great_threshhold, agreements)))\n",
    "    \n",
    "    print(f'Abysmal: {abysmal} ({to_percentage(abysmal)})')\n",
    "    print(f'Bad: {bad} ({to_percentage(bad)})')\n",
    "    print(f'Good: {good} ({to_percentage(good)})')\n",
    "    print(f'Great: {great} ({to_percentage(great)})')\n",
    "    \n",
    "count_relationship_levels(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6107df-af9e-4a37-8baa-cd0bb36389bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def friendly_edge_to_string(edge, country_buffer_1, country_buffer_2):\n",
    "    country1 = edge[0].ljust(country_buffer_1)\n",
    "    country2 = edge[1].ljust(country_buffer_2)\n",
    "    \n",
    "    total = str(edge[2]['total']).ljust(5)\n",
    "    points = str(edge[2]['points']).rjust(6)\n",
    "    agreement = round(edge[2]['agreement'] * 100, 1)\n",
    "    \n",
    "    return '{}, {} - {}/{} ({}%)'.format(country1, country2, points, total, agreement)\n",
    "\n",
    "def edge_country_1_length(edge):\n",
    "    return len(edge[0])\n",
    "\n",
    "def edge_country_2_length(edge):\n",
    "    return len(edge[1])\n",
    "\n",
    "def edge_country_2_length(edge):\n",
    "    return len(edge[1])\n",
    "\n",
    "def friendly_edge_print(edges):\n",
    "    max_cnt_1_length = max(map(edge_country_1_length, edges))\n",
    "    max_cnt_2_length = max(map(edge_country_2_length, edges))\n",
    "    for edge_str in map(lambda e: friendly_edge_to_string(e, max_cnt_1_length, max_cnt_2_length), edges):\n",
    "        print(edge_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f424b-0b69-409c-9f66-5cf85c32ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort edges by agreement\n",
    "def has_significant_total(edge):\n",
    "    return edge[2]['total'] > 75\n",
    "\n",
    "sorted_edges = sorted(net.edges(data=True), key=lambda edge: edge[2]['agreement'])\n",
    "sorted_edges =  list(__builtin__.filter(has_significant_total, sorted_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c99e5b8-8d02-4914-9cff-a99ab48ca522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show countries with the most agreement\n",
    "most_agreement_countries = sorted_edges[-10:]\n",
    "most_agreement_countries.reverse()\n",
    "friendly_edge_print(most_agreement_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545366e-a3c6-473f-b583-ed1ac38c539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show countries with the least agreement\n",
    "least_agreement_countries = sorted_edges[:10]\n",
    "friendly_edge_print(least_agreement_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee158d25-5d76-448d-8983-fa4fb1049f02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### In-group agreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df1d62-0acc-493f-88a9-5df2d7e6e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_soviet_satellites = [\"USSR\", \"POLAND\", \"CZECHOSLOVAKIA\", \"BELARUS\", \"UKRAINE\"]\n",
    "core_soviet_satellites = early_soviet_satellites + [\"BULGARIA\", \"GERMAN DEMOCRATIC REPUBLIC\", \"HUNGARY\"]\n",
    "\n",
    "eu_1991 = ['BELGIUM', 'GERMANY', 'ITALY', 'LUXEMBOURG', 'DENMARK', 'GREECE', 'PORTUGAL', 'UNITED KINGDOM', 'SPAIN', 'NETHERLANDS', 'FRANCE', 'IRELAND']\n",
    "eu_2002 = eu_1991 + ['SWEDEN', 'FINLAND', 'AUSTRIA']\n",
    "eu_2024 = eu_2002 + ['ESTONIA', 'LATVIA', 'POLAND', 'SLOVAKIA', 'SLOVENIA', 'BULGARIA', 'ROMANIA', 'CROATIA', 'LITHUANIA', 'CZECHIA', 'CYPRUS', 'MALTA', 'HUNGARY']\n",
    "eu_2024.remove('UNITED KINGDOM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209053d-7fbb-4859-bafa-3b5eb04379dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_group = []\n",
    "\n",
    "ingroup_agreements = {}\n",
    "for i in range(0, len(country_group)):\n",
    "    for j in range(i + 1, len(country_group)):\n",
    "        country_1 = country_group[i]\n",
    "        country_2 = country_group[j]\n",
    "        agreement = net[country_1][country_2]['agreement']\n",
    "        ingroup_agreements[(country_1, country_2)] = agreement\n",
    "        \n",
    "print('In-group country agreements:\\n')\n",
    "for k, v in sorted(ingroup_agreements.items(), key=lambda item: -item[1]):\n",
    "    print(f'{k[0]} - {k[1]}: {round(v * 100, 1)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0f694-6861-4224-9106-7b973ee7fa9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eabd55b-6151-45eb-8f95-92a0a48f296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minmax normalization for the cut-off graph (normalizes to [0.5, 1])\n",
    "def normalize_minmax(net):\n",
    "    weights = [ edge[2]['weight'] for edge in net.edges(data=True) ]\n",
    "\n",
    "    minw = min(weights)\n",
    "    maxw = max(weights)\n",
    "\n",
    "    for edge in net.edges(data=True):\n",
    "        weight = edge[2]['weight']\n",
    "        edge[2]['weight_my'] =  ((weight - minw) / (2 * (maxw - minw))) + 0.5\n",
    "        \n",
    "# Our custom normalization for the standard graph - Direct implementation\n",
    "def normalize_custom(net):\n",
    "    weights = [ edge[2]['weight'] for edge in net.edges(data=True) ]\n",
    "\n",
    "    maxw = max(weights)\n",
    "    meanw = statistics.fmean(weights)\n",
    "    weight_threshold = 2 * meanw - maxw\n",
    "    \n",
    "    minw = weight_threshold\n",
    "\n",
    "    for edge in net.edges(data=True):\n",
    "        weight = edge[2]['weight']\n",
    "        edge[2]['weight_my'] =  ((weight - minw) / (maxw - minw)) if weight > weight_threshold else 0\n",
    "        \n",
    "# calculate distances based on weight\n",
    "def calculate_distances(net):\n",
    "    for edge in net.edges(data=True):\n",
    "        my_weight = edge[2]['weight_my']\n",
    "        edge[2]['weight_distance'] = 1 / (my_weight if my_weight > 0 else 0.000001)\n",
    "        \n",
    "normalize_custom(net)\n",
    "normalize_minmax(cnet)\n",
    "calculate_distances(net)\n",
    "calculate_distances(cnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383cdbc5-b39f-4a31-bd25-0b3bd5c738e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_analysis(_net, nodes_to_remove = []):\n",
    "    net = _net.copy()\n",
    "    net.remove_nodes_from(nodes_to_remove)\n",
    "    \n",
    "    all_valid_distances = filter(lambda x: x < 1000, (edge[2]['weight_distance'] for edge in net.edges(data=True)))\n",
    "    print(f'Average direct distance: {statistics.mean(all_valid_distances)}')\n",
    "    print(f'Average distance: {nx.average_shortest_path_length(net, weight=\"weight_distance\")}')\n",
    "\n",
    "    diameter = nx.diameter(net, weight='weight_distance')\n",
    "    print(f'Weighted diameter: {diameter}')\n",
    "\n",
    "    if diameter > 1:\n",
    "        print('\\nNodes with longest shortest paths:')\n",
    "        periphery = nx.periphery(net, weight='weight_distance')\n",
    "        for country in periphery:\n",
    "            target = [k for k,v in nx.shortest_path_length(net, country, weight='weight_distance').items() if v == diameter]\n",
    "            print(f'{country} - {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46e982-ade9-41a9-a186-e9fb5de38ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Standard Graph:')\n",
    "distance_analysis(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c3553-3980-4776-8831-3c99129415b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cut-off Graph:')\n",
    "distance_analysis(cnet, nodes_to_remove=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f59f4-a501-4c74-9fcb-f6099e681513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.shortest_path(cnet, 'UNITED STATES', 'PALAU', weight = 'weight_distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf9d29-3f8c-41bb-9a87-6e75e49b1c62",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff91fee3-fa74-44f7-95ec-e8c51dfd97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_centrality(data, high_count=5, low_count=5):\n",
    "    vals = sorted(data.items(), key=lambda x: x[1], reverse=True)\n",
    "    vals = list(map(lambda val: (val[0], round(val[1], 1)), vals))\n",
    "    \n",
    "    if high_count > 0:\n",
    "        print('Highest values:')\n",
    "        highest_vals = vals[:high_count]\n",
    "        for val in highest_vals:\n",
    "            print(f'{val[0]}: {val[1]}');\n",
    "    \n",
    "    if low_count > 0:\n",
    "        print('\\nLowest values:')\n",
    "        lowest_vals = vals[-low_count:]\n",
    "        lowest_vals.reverse()\n",
    "        for val in lowest_vals:\n",
    "            print(f'{val[0]}: {val[1]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e949a-f90b-44cc-b31d-299cd5619a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print weighted degree centrality\n",
    "print_centrality(dict(net.degree(weight='weight')), 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219b284-65d3-4f4c-8fb7-59c08780f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard graph betweeness centrality\n",
    "print_centrality(dict(nx.betweenness_centrality(net, weight='weight_distance', normalized=False)), 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b67e90-b45a-4584-866c-a337fce3cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut-off graph betweeness centrality\n",
    "print_centrality(dict(nx.betweenness_centrality(cnet, weight='weight_distance', normalized=False)), 10, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
